import asyncio
import re
from datetime import datetime

import httpx
from bs4 import BeautifulSoup
from jinja2 import Template

from utils.models import ReadMessage
from typing import List, Optional


async def get_page_metadata_from_url(url, timeout=5):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ URL.

    –ò—â–µ—Ç:
        - og:description, meta description, twitter:description
        - og:title, <title>

    Args:
        url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        timeout: —Ç–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

    Returns:
        dict: {'description': str|None, 'title': str|None}
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        async with httpx.AsyncClient(timeout=timeout, follow_redirects=True) as client:
            response = await client.get(url, headers=headers)
            response.raise_for_status()

        # Parse HTML in thread pool to avoid blocking
        def parse_html(content):
            soup = BeautifulSoup(content, 'html.parser')
            result = {'description': None, 'title': None}

            # Try to get description from og:description or meta description
            desc_tags = ['og:description', 'description', 'twitter:description']
            for desc_name in desc_tags:
                meta = soup.find('meta', property=desc_name) or soup.find('meta', attrs={'name': desc_name})
                if meta and meta.get('content'):
                    result['description'] = meta.get('content').strip()
                    break

            # Try to get title from og:title, then <title> tag
            title_meta = soup.find('meta', property='og:title') or soup.find('meta', attrs={'name': 'title'})
            if title_meta and title_meta.get('content'):
                result['title'] = title_meta.get('content').strip()
            else:
                title_tag = soup.find('title')
                if title_tag and title_tag.string:
                    result['title'] = title_tag.string.strip()

            return result

        return await asyncio.to_thread(parse_html, response.content)
    except Exception:
        return {'description': None, 'title': None}


async def get_url_display_name(url, max_description_length=100):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–µ –∏–º—è –¥–ª—è URL.

    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
        1. Description (–µ—Å–ª–∏ ‚â§ max_description_length)
        2. Title
        3. Domain

    Args:
        url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        max_description_length: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ description

    Returns:
        str: –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º–æ–µ –∏–º—è
    """
    metadata = await get_page_metadata_from_url(url)

    # Prefer description if it's not too long
    description = metadata.get('description')
    if description and len(description) <= max_description_length:
        return description

    # Fall back to title
    title = metadata.get('title')
    if title:
        return title

    # Fallback to domain
    domain = re.sub(r'^https?://(www\.)?', '', url).split('/')[0]
    return domain


async def format_telegram_summary(msg: ReadMessage, linked_messages: List[ReadMessage] = None):
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç ReadMessage –≤ HTML –¥–ª—è Telegram.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —à–∞–±–ª–æ–Ω static/telegram_summary_template.html.

    Args:
        msg: –æ—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å summary, headline, hashtags
        linked_messages: –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ read_messages (–¥–ª—è —Å–ø–∏—Å–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤)

    Returns:
        str: HTML —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram
    """
    summary = msg.summary or ''
    summary = re.sub(r'</?body/?>', '', summary, flags=re.IGNORECASE)
    summary = re.sub(r'</?br/?>', '\n', summary, flags=re.IGNORECASE)

    hashtags = msg.hashtags or []
    for tag in hashtags:
        summary = re.sub(rf'\s*{re.escape(tag)}\b', '', summary)

    urls = msg.urls or []
    urls_block = ''
    if urls:
        if len(urls) == 1:
            urls_block = f'üåé  <a href="{urls[0]}">–ò—Å—Ç–æ—á–Ω–∏–∫</a>\n'
        elif len(urls) > 1:
            urls_block = 'üåé –ò—Å—Ç–æ—á–Ω–∏–∫–∏:\n'
            for u in urls:
                display_name = await get_url_display_name(u)
                if u:
                    urls_block += f'‚Ä¢ <a href="{u}"> {display_name} </a>\n'

    hashtags_block = ''
    if hashtags:
        hashtags_block = ' '.join(f"{tag if tag.startswith('#') else '#'+tag}" for tag in hashtags)

    headline = msg.headline or ''
    public_link = msg.public_link or ''

    summary_date = msg.msg_dttm.strftime('%Y-%m-%d') if isinstance(msg.msg_dttm, datetime) else ''

    # Build sources list from linked messages (or just the primary message)
    all_messages = linked_messages if linked_messages else [msg]
    sources = []
    for m in all_messages:
        author = m.author or ''
        link = m.public_link or ''
        if author:
            sources.append({'author': author, 'link': link})

    # Read template file in thread pool to avoid blocking
    def read_template():
        with open('static/telegram_summary_template.html', encoding='utf-8') as f:
            return Template(f.read())

    template = await asyncio.to_thread(read_template)

    text = template.render(
        public_link=public_link,
        headline=headline,
        summary_date=summary_date,
        summary=summary,
        urls_block=urls_block,
        sources=sources,
        hashtags_block=hashtags_block,
    )
    text = re.sub(r'\n\n\n', '\n', text).strip()
    return text

